{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AntiSplodge minimal example\n",
    "In this short and minimal tutorial we are going to use the \"global\" dataset located at https://www.heartcellatlas.org/.\n",
    "We are going to deconvolute major heart-based cell types to check the JSD of the method.\n",
    "\n",
    "You can download the dataset direcly from https://cellgeni.cog.sanger.ac.uk/heartcellatlas/data/global_raw.h5ad.\n",
    "\n",
    "First: \n",
    "Import the packages we need for this, remember to install them with \"pip install PACKAGE\" in your terminal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ann\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "\n",
    "import antisplodge as AS\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the required packages, load the dataset into memory, remember to have the dataset in the same folder as the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC = ann.read(\"../../data/reference/hca_harvard_gender_Female.sc.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                NRP age_group     cell_source  \\\nAAACCCAAGCTACTGT-1-H0015_apex    No     50-55  Harvard-Nuclei   \nAAACCCAGTACCGCGT-1-H0015_apex    No     50-55  Harvard-Nuclei   \nAAACCCATCAAACCCA-1-H0015_apex    No     50-55  Harvard-Nuclei   \nAAACCCATCGCAACAT-1-H0015_apex    No     50-55  Harvard-Nuclei   \nAAACCCATCTGGTCAA-1-H0015_apex    No     50-55  Harvard-Nuclei   \n...                              ..       ...             ...   \nTTTGATCTCCAATCCC-1-H0035_septum  No     45-50  Harvard-Nuclei   \nTTTGGAGAGCATCCTA-1-H0035_septum  No     45-50  Harvard-Nuclei   \nTTTGGAGGTCTAGGCC-1-H0035_septum  No     45-50  Harvard-Nuclei   \nTTTGGTTTCAAGGCTT-1-H0035_septum  No     45-50  Harvard-Nuclei   \nTTTGGTTTCGGAGCAA-1-H0035_septum  No     45-50  Harvard-Nuclei   \n\n                                                 cell_type donor  gender  \\\nAAACCCAAGCTACTGT-1-H0015_apex    Ventricular_Cardiomyocyte    H5  Female   \nAAACCCAGTACCGCGT-1-H0015_apex                    Pericytes    H5  Female   \nAAACCCATCAAACCCA-1-H0015_apex    Ventricular_Cardiomyocyte    H5  Female   \nAAACCCATCGCAACAT-1-H0015_apex                    Pericytes    H5  Female   \nAAACCCATCTGGTCAA-1-H0015_apex    Ventricular_Cardiomyocyte    H5  Female   \n...                                                    ...   ...     ...   \nTTTGATCTCCAATCCC-1-H0035_septum  Ventricular_Cardiomyocyte    H7  Female   \nTTTGGAGAGCATCCTA-1-H0035_septum        Smooth_muscle_cells    H7  Female   \nTTTGGAGGTCTAGGCC-1-H0035_septum                  Pericytes    H7  Female   \nTTTGGTTTCAAGGCTT-1-H0035_septum  Ventricular_Cardiomyocyte    H7  Female   \nTTTGGTTTCGGAGCAA-1-H0035_septum  Ventricular_Cardiomyocyte    H7  Female   \n\n                                 n_counts  n_genes  percent_mito  \\\nAAACCCAAGCTACTGT-1-H0015_apex      3182.0     1521      0.000943   \nAAACCCAGTACCGCGT-1-H0015_apex      1202.0      726      0.000832   \nAAACCCATCAAACCCA-1-H0015_apex      3804.0     1584      0.000263   \nAAACCCATCGCAACAT-1-H0015_apex      3529.0     1796      0.001700   \nAAACCCATCTGGTCAA-1-H0015_apex      3906.0     1677      0.000768   \n...                                   ...      ...           ...   \nTTTGATCTCCAATCCC-1-H0035_septum    1615.0      941      0.000000   \nTTTGGAGAGCATCCTA-1-H0035_septum     872.0      595      0.000000   \nTTTGGAGGTCTAGGCC-1-H0035_septum     806.0      608      0.002481   \nTTTGGTTTCAAGGCTT-1-H0035_septum    2470.0     1286      0.000405   \nTTTGGTTTCGGAGCAA-1-H0035_septum    5140.0     2227      0.000973   \n\n                                 percent_ribo  ... Used n_genes_by_counts  \\\nAAACCCAAGCTACTGT-1-H0015_apex        0.002200  ...  Yes              1521   \nAAACCCAGTACCGCGT-1-H0015_apex        0.000000  ...  Yes               726   \nAAACCCATCAAACCCA-1-H0015_apex        0.001314  ...  Yes              1584   \nAAACCCATCGCAACAT-1-H0015_apex        0.001133  ...  Yes              1796   \nAAACCCATCTGGTCAA-1-H0015_apex        0.001024  ...  Yes              1677   \n...                                       ...  ...  ...               ...   \nTTTGATCTCCAATCCC-1-H0035_septum      0.000619  ...  Yes               941   \nTTTGGAGAGCATCCTA-1-H0035_septum      0.001147  ...  Yes               595   \nTTTGGAGGTCTAGGCC-1-H0035_septum      0.002481  ...  Yes               608   \nTTTGGTTTCAAGGCTT-1-H0035_septum      0.000810  ...  Yes              1286   \nTTTGGTTTCGGAGCAA-1-H0035_septum      0.001751  ...  Yes              2227   \n\n                                 log1p_n_genes_by_counts total_counts  \\\nAAACCCAAGCTACTGT-1-H0015_apex                   7.327781       3182.0   \nAAACCCAGTACCGCGT-1-H0015_apex                   6.588926       1202.0   \nAAACCCATCAAACCCA-1-H0015_apex                   7.368340       3804.0   \nAAACCCATCGCAACAT-1-H0015_apex                   7.493874       3529.0   \nAAACCCATCTGGTCAA-1-H0015_apex                   7.425358       3906.0   \n...                                                  ...          ...   \nTTTGATCTCCAATCCC-1-H0035_septum                 6.848005       1615.0   \nTTTGGAGAGCATCCTA-1-H0035_septum                 6.390241        872.0   \nTTTGGAGGTCTAGGCC-1-H0035_septum                 6.411818        806.0   \nTTTGGTTTCAAGGCTT-1-H0035_septum                 7.160069       2470.0   \nTTTGGTTTCGGAGCAA-1-H0035_septum                 7.708860       5140.0   \n\n                                log1p_total_counts pct_counts_in_top_50_genes  \\\nAAACCCAAGCTACTGT-1-H0015_apex             8.065579                  35.575110   \nAAACCCAGTACCGCGT-1-H0015_apex             7.092574                  39.933444   \nAAACCCATCAAACCCA-1-H0015_apex             8.244071                  42.245005   \nAAACCCATCGCAACAT-1-H0015_apex             8.169053                  30.830264   \nAAACCCATCTGGTCAA-1-H0015_apex             8.270525                  40.117768   \n...                                            ...                        ...   \nTTTGATCTCCAATCCC-1-H0035_septum           7.387709                  29.349845   \nTTTGGAGAGCATCCTA-1-H0035_septum           6.771935                  30.733945   \nTTTGGAGGTCTAGGCC-1-H0035_septum           6.693324                  27.047146   \nTTTGGTTTCAAGGCTT-1-H0035_septum           7.812378                  31.578947   \nTTTGGTTTCGGAGCAA-1-H0035_septum           8.545003                  35.719844   \n\n                                pct_counts_in_top_100_genes  \\\nAAACCCAAGCTACTGT-1-H0015_apex                     42.520427   \nAAACCCAGTACCGCGT-1-H0015_apex                     47.920133   \nAAACCCATCAAACCCA-1-H0015_apex                     48.475289   \nAAACCCATCGCAACAT-1-H0015_apex                     37.432700   \nAAACCCATCTGGTCAA-1-H0015_apex                     46.313364   \n...                                                     ...   \nTTTGATCTCCAATCCC-1-H0035_septum                   38.823529   \nTTTGGAGAGCATCCTA-1-H0035_septum                   42.201835   \nTTTGGAGGTCTAGGCC-1-H0035_septum                   36.972705   \nTTTGGTTTCAAGGCTT-1-H0035_septum                   39.230769   \nTTTGGTTTCGGAGCAA-1-H0035_septum                   41.906615   \n\n                                pct_counts_in_top_200_genes  \\\nAAACCCAAGCTACTGT-1-H0015_apex                     51.571339   \nAAACCCAGTACCGCGT-1-H0015_apex                     56.239601   \nAAACCCATCAAACCCA-1-H0015_apex                     56.729758   \nAAACCCATCGCAACAT-1-H0015_apex                     46.188722   \nAAACCCATCTGGTCAA-1-H0015_apex                     54.557092   \n...                                                     ...   \nTTTGATCTCCAATCCC-1-H0035_septum                   51.207430   \nTTTGGAGAGCATCCTA-1-H0035_septum                   54.701835   \nTTTGGAGGTCTAGGCC-1-H0035_septum                   49.379653   \nTTTGGTTTCAAGGCTT-1-H0035_septum                   49.473684   \nTTTGGTTTCGGAGCAA-1-H0035_septum                   49.747082   \n\n                                 pct_counts_in_top_500_genes  .split  \nAAACCCAAGCTACTGT-1-H0015_apex                      67.913262   train  \nAAACCCAGTACCGCGT-1-H0015_apex                      81.198003   train  \nAAACCCATCAAACCCA-1-H0015_apex                      71.503680   train  \nAAACCCATCGCAACAT-1-H0015_apex                      63.247379   train  \nAAACCCATCTGGTCAA-1-H0015_apex                      69.866871   train  \n...                                                      ...     ...  \nTTTGATCTCCAATCCC-1-H0035_septum                    72.693498   train  \nTTTGGAGAGCATCCTA-1-H0035_septum                    89.105505   train  \nTTTGGAGGTCTAGGCC-1-H0035_septum                    86.600496   train  \nTTTGGTTTCAAGGCTT-1-H0035_septum                    68.178138   train  \nTTTGGTTTCGGAGCAA-1-H0035_septum                    63.210117   train  \n\n[44898 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NRP</th>\n      <th>age_group</th>\n      <th>cell_source</th>\n      <th>cell_type</th>\n      <th>donor</th>\n      <th>gender</th>\n      <th>n_counts</th>\n      <th>n_genes</th>\n      <th>percent_mito</th>\n      <th>percent_ribo</th>\n      <th>...</th>\n      <th>Used</th>\n      <th>n_genes_by_counts</th>\n      <th>log1p_n_genes_by_counts</th>\n      <th>total_counts</th>\n      <th>log1p_total_counts</th>\n      <th>pct_counts_in_top_50_genes</th>\n      <th>pct_counts_in_top_100_genes</th>\n      <th>pct_counts_in_top_200_genes</th>\n      <th>pct_counts_in_top_500_genes</th>\n      <th>.split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AAACCCAAGCTACTGT-1-H0015_apex</th>\n      <td>No</td>\n      <td>50-55</td>\n      <td>Harvard-Nuclei</td>\n      <td>Ventricular_Cardiomyocyte</td>\n      <td>H5</td>\n      <td>Female</td>\n      <td>3182.0</td>\n      <td>1521</td>\n      <td>0.000943</td>\n      <td>0.002200</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>1521</td>\n      <td>7.327781</td>\n      <td>3182.0</td>\n      <td>8.065579</td>\n      <td>35.575110</td>\n      <td>42.520427</td>\n      <td>51.571339</td>\n      <td>67.913262</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>AAACCCAGTACCGCGT-1-H0015_apex</th>\n      <td>No</td>\n      <td>50-55</td>\n      <td>Harvard-Nuclei</td>\n      <td>Pericytes</td>\n      <td>H5</td>\n      <td>Female</td>\n      <td>1202.0</td>\n      <td>726</td>\n      <td>0.000832</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>726</td>\n      <td>6.588926</td>\n      <td>1202.0</td>\n      <td>7.092574</td>\n      <td>39.933444</td>\n      <td>47.920133</td>\n      <td>56.239601</td>\n      <td>81.198003</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>AAACCCATCAAACCCA-1-H0015_apex</th>\n      <td>No</td>\n      <td>50-55</td>\n      <td>Harvard-Nuclei</td>\n      <td>Ventricular_Cardiomyocyte</td>\n      <td>H5</td>\n      <td>Female</td>\n      <td>3804.0</td>\n      <td>1584</td>\n      <td>0.000263</td>\n      <td>0.001314</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>1584</td>\n      <td>7.368340</td>\n      <td>3804.0</td>\n      <td>8.244071</td>\n      <td>42.245005</td>\n      <td>48.475289</td>\n      <td>56.729758</td>\n      <td>71.503680</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>AAACCCATCGCAACAT-1-H0015_apex</th>\n      <td>No</td>\n      <td>50-55</td>\n      <td>Harvard-Nuclei</td>\n      <td>Pericytes</td>\n      <td>H5</td>\n      <td>Female</td>\n      <td>3529.0</td>\n      <td>1796</td>\n      <td>0.001700</td>\n      <td>0.001133</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>1796</td>\n      <td>7.493874</td>\n      <td>3529.0</td>\n      <td>8.169053</td>\n      <td>30.830264</td>\n      <td>37.432700</td>\n      <td>46.188722</td>\n      <td>63.247379</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>AAACCCATCTGGTCAA-1-H0015_apex</th>\n      <td>No</td>\n      <td>50-55</td>\n      <td>Harvard-Nuclei</td>\n      <td>Ventricular_Cardiomyocyte</td>\n      <td>H5</td>\n      <td>Female</td>\n      <td>3906.0</td>\n      <td>1677</td>\n      <td>0.000768</td>\n      <td>0.001024</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>1677</td>\n      <td>7.425358</td>\n      <td>3906.0</td>\n      <td>8.270525</td>\n      <td>40.117768</td>\n      <td>46.313364</td>\n      <td>54.557092</td>\n      <td>69.866871</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>TTTGATCTCCAATCCC-1-H0035_septum</th>\n      <td>No</td>\n      <td>45-50</td>\n      <td>Harvard-Nuclei</td>\n      <td>Ventricular_Cardiomyocyte</td>\n      <td>H7</td>\n      <td>Female</td>\n      <td>1615.0</td>\n      <td>941</td>\n      <td>0.000000</td>\n      <td>0.000619</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>941</td>\n      <td>6.848005</td>\n      <td>1615.0</td>\n      <td>7.387709</td>\n      <td>29.349845</td>\n      <td>38.823529</td>\n      <td>51.207430</td>\n      <td>72.693498</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>TTTGGAGAGCATCCTA-1-H0035_septum</th>\n      <td>No</td>\n      <td>45-50</td>\n      <td>Harvard-Nuclei</td>\n      <td>Smooth_muscle_cells</td>\n      <td>H7</td>\n      <td>Female</td>\n      <td>872.0</td>\n      <td>595</td>\n      <td>0.000000</td>\n      <td>0.001147</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>595</td>\n      <td>6.390241</td>\n      <td>872.0</td>\n      <td>6.771935</td>\n      <td>30.733945</td>\n      <td>42.201835</td>\n      <td>54.701835</td>\n      <td>89.105505</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>TTTGGAGGTCTAGGCC-1-H0035_septum</th>\n      <td>No</td>\n      <td>45-50</td>\n      <td>Harvard-Nuclei</td>\n      <td>Pericytes</td>\n      <td>H7</td>\n      <td>Female</td>\n      <td>806.0</td>\n      <td>608</td>\n      <td>0.002481</td>\n      <td>0.002481</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>608</td>\n      <td>6.411818</td>\n      <td>806.0</td>\n      <td>6.693324</td>\n      <td>27.047146</td>\n      <td>36.972705</td>\n      <td>49.379653</td>\n      <td>86.600496</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>TTTGGTTTCAAGGCTT-1-H0035_septum</th>\n      <td>No</td>\n      <td>45-50</td>\n      <td>Harvard-Nuclei</td>\n      <td>Ventricular_Cardiomyocyte</td>\n      <td>H7</td>\n      <td>Female</td>\n      <td>2470.0</td>\n      <td>1286</td>\n      <td>0.000405</td>\n      <td>0.000810</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>1286</td>\n      <td>7.160069</td>\n      <td>2470.0</td>\n      <td>7.812378</td>\n      <td>31.578947</td>\n      <td>39.230769</td>\n      <td>49.473684</td>\n      <td>68.178138</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>TTTGGTTTCGGAGCAA-1-H0035_septum</th>\n      <td>No</td>\n      <td>45-50</td>\n      <td>Harvard-Nuclei</td>\n      <td>Ventricular_Cardiomyocyte</td>\n      <td>H7</td>\n      <td>Female</td>\n      <td>5140.0</td>\n      <td>2227</td>\n      <td>0.000973</td>\n      <td>0.001751</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>2227</td>\n      <td>7.708860</td>\n      <td>5140.0</td>\n      <td>8.545003</td>\n      <td>35.719844</td>\n      <td>41.906615</td>\n      <td>49.747082</td>\n      <td>63.210117</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>44898 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SC.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the number of cells remaining (N=163959)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 44898 × 33538\n",
      "    obs: 'NRP', 'age_group', 'cell_source', 'cell_type', 'donor', 'gender', 'n_counts', 'n_genes', 'percent_mito', 'percent_ribo', 'region', 'sample', 'scrublet_score', 'source', 'type', 'version', 'cell_states', 'Used', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', '.split'\n",
      "    var: 'gene_ids-Harvard-Nuclei', 'feature_types-Harvard-Nuclei', 'gene_ids-Sanger-Nuclei', 'feature_types-Sanger-Nuclei', 'gene_ids-Sanger-Cells', 'feature_types-Sanger-Cells', 'gene_ids-Sanger-CD45', 'feature_types-Sanger-CD45', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts'\n",
      "    uns: 'cell_type_colors'\n",
      "    obsm: 'X_pca', 'X_umap'\n"
     ]
    }
   ],
   "source": [
    "print(SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find marker genes\n",
    "Because of the high number of genes (N=33538), we want to reduce the set of genes to a smaller one in order to speed up training and reduce memory footprint. But it would work with all the genes, but the time to get an as good model will be a lot higher. \n",
    "\n",
    "However, before we look for marker genes, we scale all profiles to 1 using scanpy's function normalize_total, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC.layers[\"norm\"] = sc.pp.normalize_total(SC, target_sum=1, inplace=False)[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Find the top 'key' marker genes that was found for each cell type during the univariate t-test analysis \n",
    "#\n",
    "# usually you should use method='logreg', but t-test is faster for demonstration purpose\n",
    "sc.tl.rank_genes_groups(SC, groupby='cell_type', method='t-test', layer=\"norm\", use_raw=False, key_added='ranks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adipocytes 50\n",
      "Atrial_Cardiomyocyte 50\n",
      "Endothelial 50\n",
      "Fibroblast 50\n",
      "Lymphoid 50\n",
      "Myeloid 50\n",
      "Neuronal 50\n",
      "Pericytes 76\n",
      "Smooth_muscle_cells 50\n",
      "Ventricular_Cardiomyocyte 344\n",
      "Length of unique genes: 736\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Get the corresponding gene sets\n",
    "#\n",
    "def getGenes(adata, key, ct, min_genes, score_threshold=0.01):\n",
    "    genes = []\n",
    "    \n",
    "    # get the N most correlated genes for each cell type\n",
    "    for i, cell_ in enumerate(ct):\n",
    "        \n",
    "        # find the number of genes to include\n",
    "        index = min_genes \n",
    "        while adata.uns[key]['scores'][cell_][index] > score_threshold: # hardcoded 0.01 inclusion \n",
    "            index += 1\n",
    "        \n",
    "        genes_ = adata.uns[key]['names'][cell_][0:index]\n",
    "        scores = adata.uns[key]['scores'][cell_][0:index]\n",
    "        \n",
    "        print(cell_, len(genes_))\n",
    "        \n",
    "        genes.extend(genes_)\n",
    "        \n",
    "    np_genes = np.unique(np.array(genes))\n",
    "    print(\"Length of unique genes:\",len(np_genes))\n",
    "    \n",
    "    return np_genes\n",
    "\n",
    "# use the top 50 for cell_type and allow some threshold to select the rest, \n",
    "# only ventricular cardiomyocytes have genes with scores above this threshold\n",
    "gene_set = getGenes(SC, 'ranks', np.unique(SC.obs['cell_type']), 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC = SC[:,gene_set] # filter SC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to scale again after removing unwanted genes, in order to again, have profiles of equal counts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/potti/Documents/HPI/thesis/spatialtranscriptomics/st_data_gen/.venv/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    }
   ],
   "source": [
    "sc.pp.normalize_total(SC, target_sum=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 44898 × 736\n",
      "    obs: 'NRP', 'age_group', 'cell_source', 'cell_type', 'donor', 'gender', 'n_counts', 'n_genes', 'percent_mito', 'percent_ribo', 'region', 'sample', 'scrublet_score', 'source', 'type', 'version', 'cell_states', 'Used', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', '.split'\n",
      "    var: 'gene_ids-Harvard-Nuclei', 'feature_types-Harvard-Nuclei', 'gene_ids-Sanger-Nuclei', 'feature_types-Sanger-Nuclei', 'gene_ids-Sanger-Cells', 'feature_types-Sanger-Cells', 'gene_ids-Sanger-CD45', 'feature_types-Sanger-CD45', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts'\n",
      "    uns: 'cell_type_colors', 'ranks'\n",
      "    obsm: 'X_pca', 'X_umap'\n",
      "    layers: 'norm'\n"
     ]
    }
   ],
   "source": [
    "# the profiles are now much smaller which will reduce memory and speed up traininig time\n",
    "print(SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AntiSplodge experiment\n",
    "We then setup the AntiSplodge experiment, in this step we do:\n",
    "\n",
    "1) Create a new experiment by passing SC to the AntiSplodge 'DeconvolutionExperiment' function.\n",
    "2) We set the cell type column to 'cell_type' in the dataset\n",
    "3) We split the dataset into 80% train, 10% validation, and, 10% test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = AS.DeconvolutionExperiment(SC)\n",
    "\n",
    "experiment.setVerbosity(True)\n",
    "\n",
    "# CELLTYPE_COLUMN should be replaced with actual column\n",
    "experiment.setCellTypeColumn('cell_type')\n",
    "# Use 80% as train data and split the rest into a 50/50 split validation and testing\n",
    "experiment.splitTrainTestValidation(train=0.8, rest=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we generate 500.000 training, 10.000 validation, and, 10.000 test samples. \n",
    "And load these into data loaders for use in training of the neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING PROFILES\n",
      "GENERATING TRAIN DATASET (N=500000)\n",
      "GENERATING VALIDATION DATASET (N=10000)\n",
      "GENERATING TEST DATASET (N=10000)\n"
     ]
    }
   ],
   "source": [
    "experiment.generateTrainTestValidation(num_profiles=[500000,10000,10000], CD=[10,10])\n",
    "# Load the profiles into data loaders\n",
    "experiment.setupDataLoaders(batch_size=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the model (with default values) and use the first cuda device (cuda_id=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CUDA) device is: cpu\n"
     ]
    }
   ],
   "source": [
    "# Initialize Neural network-model and allocate it to the cuda_id specified\n",
    "# Use 'cuda_id=\"cpu\"' if you want to allocate it to a cpu\n",
    "experiment.setupModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train the network with 25 warm restarts, this means whenever we finish a training session we load the best model settings we have found so far back onto the model and continue from there in the next setting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training experiment for dataset\n",
      "Epoch: 001 | Epochs since last increase: 000\n",
      "Loss: (Train) 0.01422 | (Valid): 0.01678 - (mean)JSD: (Train) 0.08914 | (Valid) 0.10575 \n",
      "\n",
      "Epoch: 002 | Epochs since last increase: 001\n",
      "Loss: (Train) 0.01326 | (Valid): 0.01733 - (mean)JSD: (Train) 0.09444 | (Valid) 0.11322 \n",
      "\n",
      "Epoch: 003 | Epochs since last increase: 000 | Better solution found\n",
      "Loss: (Train) 0.01290 | (Valid): 0.01578 - (mean)JSD: (Train) 0.08748 | (Valid) 0.10299 \n",
      "\n",
      "Epoch: 004 | Epochs since last increase: 000 | Better solution found\n",
      "Loss: (Train) 0.01271 | (Valid): 0.01517 - (mean)JSD: (Train) 0.08233 | (Valid) 0.10082 \n",
      "\n",
      "Epoch: 005 | Epochs since last increase: 000 | Better solution found\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [21], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m experiment\u001B[38;5;241m.\u001B[39msetupOptimizerAndCriterion(learning_rate \u001B[38;5;241m=\u001B[39m lr)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Train the experiment constructed by passing the experiment to the AntiSplodge training function\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m \u001B[43mAS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexperiment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mModelCheckpoint.pt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbest_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbest_error\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# For longer training, increase patience threshold\u001B[39;00m\n\u001B[1;32m     17\u001B[0m best_error \u001B[38;5;241m=\u001B[39m AS\u001B[38;5;241m.\u001B[39mgetMeanJSD(experiment, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;66;03m# set best error as the target error to beat\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRestart [\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m] - JSDs\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(k),AS\u001B[38;5;241m.\u001B[39mgetMeanJSD(experiment, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m), AS\u001B[38;5;241m.\u001B[39mgetMeanJSD(experiment, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[0;32m~/Documents/HPI/thesis/spatialtranscriptomics/st_data_gen/.venv/lib/python3.9/site-packages/antisplodge.py:660\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(experiment, patience, save_file, auto_load_model_on_finish, best_loss, validation_metric)\u001B[0m\n\u001B[1;32m    658\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m experiment\u001B[38;5;241m.\u001B[39mverbose:\n\u001B[1;32m    659\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me_\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m0\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | Epochs since last increase: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m(p_\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m0\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m | Better solution found\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m found_better_weights \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m--> 660\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoss: (Train) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtel\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | (Valid): \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvel\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m - (mean)JSD: (Train) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgetMeanJSD(experiment, split_dataset\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | (Valid) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgetMeanJSD(experiment, split_dataset\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    661\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    663\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinished training (checkpoint saved in: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(save_file))\n",
      "File \u001B[0;32m~/Documents/HPI/thesis/spatialtranscriptomics/st_data_gen/.venv/lib/python3.9/site-packages/antisplodge.py:745\u001B[0m, in \u001B[0;36mgetMeanJSD\u001B[0;34m(experiment, split_dataset, show_warning)\u001B[0m\n\u001B[1;32m    743\u001B[0m jsds_ \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    744\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(y_preds)):\n\u001B[0;32m--> 745\u001B[0m     jsds_\u001B[38;5;241m.\u001B[39mappend(\u001B[43mdistance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjensenshannon\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproportions\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_preds\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    747\u001B[0m nan_counts \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mcount_nonzero(np\u001B[38;5;241m.\u001B[39misnan(jsds_))\n\u001B[1;32m    748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m nan_counts \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m show_warning:\n",
      "File \u001B[0;32m~/Documents/HPI/thesis/spatialtranscriptomics/st_data_gen/.venv/lib/python3.9/site-packages/scipy/spatial/distance.py:1292\u001B[0m, in \u001B[0;36mjensenshannon\u001B[0;34m(p, q, base, axis, keepdims)\u001B[0m\n\u001B[1;32m   1290\u001B[0m left \u001B[38;5;241m=\u001B[39m rel_entr(p, m)\n\u001B[1;32m   1291\u001B[0m right \u001B[38;5;241m=\u001B[39m rel_entr(q, m)\n\u001B[0;32m-> 1292\u001B[0m left_sum \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeepdims\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1293\u001B[0m right_sum \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(right, axis\u001B[38;5;241m=\u001B[39maxis, keepdims\u001B[38;5;241m=\u001B[39mkeepdims)\n\u001B[1;32m   1294\u001B[0m js \u001B[38;5;241m=\u001B[39m left_sum \u001B[38;5;241m+\u001B[39m right_sum\n",
      "File \u001B[0;32m<__array_function__ internals>:177\u001B[0m, in \u001B[0;36msum\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# do 25 warm restarts with decreasing learning rate\n",
    "print(\"Training experiment for dataset\")\n",
    "lr = 0.001\n",
    "best_error=None # no target error to beat in the beginning\n",
    "for k in range(25):\n",
    "\n",
    "    # Consider changing learning rate (lr) during run more dynamically\n",
    "    if k >= 5:\n",
    "        lr = 0.0005\n",
    "    if k >= 10:\n",
    "        lr = 0.0001\n",
    "    if k >= 15:\n",
    "        lr = 0.00005\n",
    "    experiment.setupOptimizerAndCriterion(learning_rate = lr)\n",
    "    # Train the experiment constructed by passing the experiment to the AntiSplodge training function\n",
    "    AS.train(experiment, save_file=\"ModelCheckpoint.pt\", patience=5, best_loss=best_error) # For longer training, increase patience threshold\n",
    "    best_error = AS.getMeanJSD(experiment, \"validation\") # set best error as the target error to beat\n",
    "\n",
    "    print(\"Restart [{}] - JSDs\".format(k),AS.getMeanJSD(experiment, \"train\"), AS.getMeanJSD(experiment, \"validation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harvard-Nuclei Test mean JSDs: 8.354745%\n",
      "Sanger-Nuclei Test mean JSDs: 9.354040%\n",
      "Sanger-Cells Test mean JSDs: 9.200285%\n",
      "Sanger-CD45 Test mean JSDs: 9.146629%\n"
     ]
    }
   ],
   "source": [
    "for dat in dataset_strings:\n",
    "    print(dat, \"Test mean JSDs:\", \"{:2f}%\".format(AS.getMeanJSD(experiments[dat], \"test\")*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dat in dataset_strings:\n",
    "    experiments[dat].SC_train.write(\"{}_SC_train.h5ad\".format(dat))\n",
    "    experiments[dat].SC_val.write(\"{}_SC_val.h5ad\".format(dat))\n",
    "    experiments[dat].SC_test.write(\"{}_SC_test.h5ad\".format(dat))\n",
    "    \n",
    "    np.savez_compressed(\n",
    "        \"{}_HCA_Dataset_for_Fabian.npz\".format(dat),\n",
    "        #X_train=np.array(experiments[dat].X_train),\n",
    "        #X_val=np.array(experiments[dat].X_val),\n",
    "        ST_X_test=np.array(experiments[dat].X_test),\n",
    "        \n",
    "        #Y_train=np.array(experiments[dat].Y_train_prop),\n",
    "        #Y_val=np.array(experiments[dat].Y_val_prop),\n",
    "        ST_Y_test=np.array(experiments[dat].Y_test_prop),\n",
    "        \n",
    "        genes=gene_sets[dat],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
