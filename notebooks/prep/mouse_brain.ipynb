{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23125ad-4c45-4961-8210-e2181061527a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Mouse Whole Cortex and Hippocampus 10x\n",
    "Source: [Allen Brain Map](https://portal.brain-map.org/atlases-and-data/rnaseq/mouse-whole-cortex-and-hippocampus-10x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c815f3ef-32a6-45b7-997f-d572ecf96325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.sparse import csr_matrix, bmat\n",
    "import multiprocessing\n",
    "\n",
    "from util import download\n",
    "import hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a779f7b9-b03a-4f50-b8b3-771e66115f80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf1a3b-561e-45c5-b828-ead8ea21bc9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "We fetch the necessary files to construct the AnnData object:\n",
    "* Count Matrix (HDF5)\n",
    "* Cell Metadata (CSV)\n",
    "* UMAP Coordinates (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7acc217f-c9b5-47d7-b65f-ee39e3e5e53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "expression_matrix.hdf5: 0.00iB [00:00, ?iB/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95d385d0f0a04174943a0094c6fada06"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m expression_path \u001B[38;5;241m=\u001B[39m \u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhttps://idk-etl-prod-download-bucket.s3.amazonaws.com/aibs_mouse_ctx-hpf_10x/expression_matrix.hdf5\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m metadata_path \u001B[38;5;241m=\u001B[39m download(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://idk-etl-prod-download-bucket.s3.amazonaws.com/aibs_mouse_ctx-hpf_10x/metadata.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m coordinates_path \u001B[38;5;241m=\u001B[39m download(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://idk-etl-prod-download-bucket.s3.amazonaws.com/aibs_mouse_ctx-hpf_10x/tsne.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/thesis/workspace/prep/util.py:29\u001B[0m, in \u001B[0;36mdownload\u001B[0;34m(url, directory, filename)\u001B[0m\n\u001B[1;32m     27\u001B[0m progress\u001B[38;5;241m.\u001B[39mset_postfix(status\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdownloading\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 29\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m(partial(r\u001B[38;5;241m.\u001B[39mread, BLOCKSIZE), \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     30\u001B[0m         progress\u001B[38;5;241m.\u001B[39mupdate(f\u001B[38;5;241m.\u001B[39mwrite(chunk))\n\u001B[1;32m     31\u001B[0m progress\u001B[38;5;241m.\u001B[39mset_postfix(status\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdownloaded\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/conda3/envs/workspace/lib/python3.10/http/client.py:465\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength:\n\u001B[1;32m    463\u001B[0m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[1;32m    464\u001B[0m     amt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength\n\u001B[0;32m--> 465\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    468\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    469\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m~/conda3/envs/workspace/lib/python3.10/socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/conda3/envs/workspace/lib/python3.10/ssl.py:1273\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1269\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1270\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1271\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1272\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1273\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1274\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1275\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m~/conda3/envs/workspace/lib/python3.10/ssl.py:1129\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1129\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1130\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1131\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "expression_path = download(\"https://idk-etl-prod-download-bucket.s3.amazonaws.com/aibs_mouse_ctx-hpf_10x/expression_matrix.hdf5\")\n",
    "metadata_path = download(\"https://idk-etl-prod-download-bucket.s3.amazonaws.com/aibs_mouse_ctx-hpf_10x/metadata.csv\")\n",
    "coordinates_path = download(\"https://idk-etl-prod-download-bucket.s3.amazonaws.com/aibs_mouse_ctx-hpf_10x/tsne.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe34a0d-5945-4939-aec9-0aab2457912c",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, we import the counts data and create the AnnData Object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92bdff2-b51b-425f-959a-d9d9c19af1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data':\t<HDF5 group \"/data\" (4 members)>\n",
      " |- 'counts':\t<HDF5 dataset \"counts\": shape (31053, 1169320), type \"<i4\">\n",
      " |- 'gene':\t<HDF5 dataset \"gene\": shape (31053,), type \"|S30\">\n",
      " |- 'samples':\t<HDF5 dataset \"samples\": shape (1169320,), type \"|S36\">\n",
      " |- 'shape':\t<HDF5 dataset \"shape\": shape (2,), type \"<i4\">\n"
     ]
    }
   ],
   "source": [
    "expression_file = hdf5.load(expression_path)\n",
    "hdf5.tree(expression_file)\n",
    "expression = expression_file[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5154f8-b67b-42e1-baf5-ececdc886acc",
   "metadata": {},
   "source": [
    "Read large matrix in chunk steps, such that it does not use to much memory.\n",
    "\n",
    "**WARNING:** This step uses a lot (>60GiB) of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fdfc4f-9d9e-458a-91b4-51ace2ad08cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "/data/counts:   0%|          | 0/3744 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0502202b3184e4ca99923d8d363db36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = expression[\"counts\"]\n",
    "m = hdf5.read_sparse_chunks(counts, sparse_format=csr_matrix, transpose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e71ad31-4864-475a-b613-7ccc13f57bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = bmat(m)\n",
    "mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f966cfca-b823-43bc-aef4-e6348ccc8a22",
   "metadata": {},
   "source": [
    "We construct the AnnData object by attaching the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac19ae93-7a8d-4b2d-9e93-14ee31ec9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ad.AnnData(X=m, dtype=m.dtype)\n",
    "dataset.obs_names = expression[\"samples\"]\n",
    "dataset.var_names = expression[\"gene\"]\n",
    "dataset.write(\"mouse_brain_raw.sc.h5ad\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e80b5-1319-482c-9c4d-820d665595fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = csr_matrix([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7679bda-65ca-44b6-891e-b7f685dc1ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.asformat(\"csr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/scratch/fabian.pottbaecker/226501'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TMPDIR\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "a = np.full((2,2), None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from scipy.sparse import random\n",
    "a[0,0] = random(100,100, format=\"csr\")\n",
    "a[0,1] = random(100,100, format=\"csr\")\n",
    "a[1,0] = random(100,100, format=\"csr\")\n",
    "a[1,1] = random(100,100, format=\"csr\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<100x100 sparse matrix of type '<class 'numpy.float64'>'\n\twith 100 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<200x200 sparse matrix of type '<class 'numpy.float64'>'\n\twith 400 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmat(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import inspect"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def bmat(blocks, format=None, dtype=None):\n",
      "    \"\"\"\n",
      "    Build a sparse matrix from sparse sub-blocks\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    blocks : array_like\n",
      "        Grid of sparse matrices with compatible shapes.\n",
      "        An entry of None implies an all-zero matrix.\n",
      "    format : {'bsr', 'coo', 'csc', 'csr', 'dia', 'dok', 'lil'}, optional\n",
      "        The sparse format of the result (e.g. \"csr\"). By default an\n",
      "        appropriate sparse matrix format is returned.\n",
      "        This choice is subject to change.\n",
      "    dtype : dtype, optional\n",
      "        The data-type of the output matrix. If not given, the dtype is\n",
      "        determined from that of `blocks`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    bmat : sparse matrix\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    block_diag, diags\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy.sparse import coo_matrix, bmat\n",
      "    >>> A = coo_matrix([[1, 2], [3, 4]])\n",
      "    >>> B = coo_matrix([[5], [6]])\n",
      "    >>> C = coo_matrix([[7]])\n",
      "    >>> bmat([[A, B], [None, C]]).toarray()\n",
      "    array([[1, 2, 5],\n",
      "           [3, 4, 6],\n",
      "           [0, 0, 7]])\n",
      "\n",
      "    >>> bmat([[A, None], [None, C]]).toarray()\n",
      "    array([[1, 2, 0],\n",
      "           [3, 4, 0],\n",
      "           [0, 0, 7]])\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    blocks = np.asarray(blocks, dtype='object')\n",
      "\n",
      "    if blocks.ndim != 2:\n",
      "        raise ValueError('blocks must be 2-D')\n",
      "\n",
      "    M,N = blocks.shape\n",
      "\n",
      "    # check for fast path cases\n",
      "    if (format in (None, 'csr') and all(isinstance(b, csr_matrix)\n",
      "                                        for b in blocks.flat)):\n",
      "        if N > 1:\n",
      "            # stack along columns (axis 1):\n",
      "            blocks = [[_stack_along_minor_axis(blocks[b, :], 1)]\n",
      "                      for b in range(M)]   # must have shape: (M, 1)\n",
      "            blocks = np.asarray(blocks, dtype='object')\n",
      "\n",
      "        # stack along rows (axis 0):\n",
      "        A = _compressed_sparse_stack(blocks[:, 0], 0)\n",
      "        if dtype is not None:\n",
      "            A = A.astype(dtype)\n",
      "        return A\n",
      "    elif (format in (None, 'csc') and all(isinstance(b, csc_matrix)\n",
      "                                          for b in blocks.flat)):\n",
      "        if M > 1:\n",
      "            # stack along rows (axis 0):\n",
      "            blocks = [[_stack_along_minor_axis(blocks[:, b], 0)\n",
      "                       for b in range(N)]]   # must have shape: (1, N)\n",
      "            blocks = np.asarray(blocks, dtype='object')\n",
      "\n",
      "        # stack along columns (axis 1):\n",
      "        A = _compressed_sparse_stack(blocks[0, :], 1)\n",
      "        if dtype is not None:\n",
      "            A = A.astype(dtype)\n",
      "        return A\n",
      "\n",
      "    block_mask = np.zeros(blocks.shape, dtype=bool)\n",
      "    brow_lengths = np.zeros(M, dtype=np.int64)\n",
      "    bcol_lengths = np.zeros(N, dtype=np.int64)\n",
      "\n",
      "    # convert everything to COO format\n",
      "    for i in range(M):\n",
      "        for j in range(N):\n",
      "            if blocks[i,j] is not None:\n",
      "                A = coo_matrix(blocks[i,j])\n",
      "                blocks[i,j] = A\n",
      "                block_mask[i,j] = True\n",
      "\n",
      "                if brow_lengths[i] == 0:\n",
      "                    brow_lengths[i] = A.shape[0]\n",
      "                elif brow_lengths[i] != A.shape[0]:\n",
      "                    msg = (f'blocks[{i},:] has incompatible row dimensions. '\n",
      "                           f'Got blocks[{i},{j}].shape[0] == {A.shape[0]}, '\n",
      "                           f'expected {brow_lengths[i]}.')\n",
      "                    raise ValueError(msg)\n",
      "\n",
      "                if bcol_lengths[j] == 0:\n",
      "                    bcol_lengths[j] = A.shape[1]\n",
      "                elif bcol_lengths[j] != A.shape[1]:\n",
      "                    msg = (f'blocks[:,{j}] has incompatible column '\n",
      "                           f'dimensions. '\n",
      "                           f'Got blocks[{i},{j}].shape[1] == {A.shape[1]}, '\n",
      "                           f'expected {bcol_lengths[j]}.')\n",
      "                    raise ValueError(msg)\n",
      "\n",
      "    nnz = sum(block.nnz for block in blocks[block_mask])\n",
      "    if dtype is None:\n",
      "        all_dtypes = [blk.dtype for blk in blocks[block_mask]]\n",
      "        dtype = upcast(*all_dtypes) if all_dtypes else None\n",
      "\n",
      "    row_offsets = np.append(0, np.cumsum(brow_lengths))\n",
      "    col_offsets = np.append(0, np.cumsum(bcol_lengths))\n",
      "\n",
      "    shape = (row_offsets[-1], col_offsets[-1])\n",
      "\n",
      "    data = np.empty(nnz, dtype=dtype)\n",
      "    idx_dtype = get_index_dtype(maxval=max(shape))\n",
      "    row = np.empty(nnz, dtype=idx_dtype)\n",
      "    col = np.empty(nnz, dtype=idx_dtype)\n",
      "\n",
      "    nnz = 0\n",
      "    ii, jj = np.nonzero(block_mask)\n",
      "    for i, j in zip(ii, jj):\n",
      "        B = blocks[i, j]\n",
      "        idx = slice(nnz, nnz + B.nnz)\n",
      "        data[idx] = B.data\n",
      "        np.add(B.row, row_offsets[i], out=row[idx], dtype=idx_dtype)\n",
      "        np.add(B.col, col_offsets[j], out=col[idx], dtype=idx_dtype)\n",
      "        nnz += B.nnz\n",
      "\n",
      "    return coo_matrix((data, (row, col)), shape=shape).asformat(format)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(bmat))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'1.7.3'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.__version__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43msc\u001B[49m\u001B[38;5;241m.\u001B[39m__version__\n",
      "\u001B[0;31mNameError\u001B[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "sc.__version__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
